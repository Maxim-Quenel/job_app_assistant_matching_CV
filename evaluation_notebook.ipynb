{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Job App Assistant Evaluation Notebook\n",
        "\n",
        "This notebook evaluates the matching pipeline with example requests,\n",
        "proxy precision metrics, and latency charts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project overview\n",
        "\n",
        "- Step 1: scrape or parse job offers into `data/jobs_raw.csv`.\n",
        "- Step 2: rewrite job offers with an LLM into `data/jobs_rewritten.csv`.\n",
        "- Step 3: convert a PDF CV into `data/cv_converted.txt`.\n",
        "- Step 4: rewrite and summarize the CV into `data/cv_synthesized.txt`.\n",
        "- Step 5: embedding matching -> `data/final_matches.csv`.\n",
        "- Step 6: cross-encoder reranking -> `data/final_matches_cross.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "DATA_DIR = os.path.join(os.getcwd(), \"data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_read_csv(path):\n",
        "    if os.path.exists(path):\n",
        "        return pd.read_csv(path)\n",
        "    return None\n",
        "\n",
        "jobs_raw_path = os.path.join(DATA_DIR, \"jobs_raw.csv\")\n",
        "jobs_rewritten_path = os.path.join(DATA_DIR, \"jobs_rewritten.csv\")\n",
        "matches_embed_path = os.path.join(DATA_DIR, \"final_matches.csv\")\n",
        "matches_cross_path = os.path.join(DATA_DIR, \"final_matches_cross.csv\")\n",
        "cv_path = os.path.join(DATA_DIR, \"cv_synthesized.txt\")\n",
        "\n",
        "jobs_raw = safe_read_csv(jobs_raw_path)\n",
        "jobs_rewritten = safe_read_csv(jobs_rewritten_path)\n",
        "matches_embed = safe_read_csv(matches_embed_path)\n",
        "matches_cross = safe_read_csv(matches_cross_path)\n",
        "\n",
        "cv_text = None\n",
        "if os.path.exists(cv_path):\n",
        "    with open(cv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        cv_text = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example requests\n",
        "\n",
        "These examples mirror the Flask API in `app.py`. Run the server separately\n",
        "if you want to execute them against `http://localhost:5000`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"step\": \"step1_scrape\",\n",
        "        \"endpoint\": \"/api/step1\",\n",
        "        \"payload\": {\"mode\": \"scrape\", \"keyword\": \"Data Analyst\", \"num_jobs\": 5}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step1_text\",\n",
        "        \"endpoint\": \"/api/step1\",\n",
        "        \"payload\": {\"mode\": \"text\", \"text\": \"Paste raw job offer text here...\"}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step2_rewrite_jobs\",\n",
        "        \"endpoint\": \"/api/step2\",\n",
        "        \"payload\": {}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step3_upload_cv\",\n",
        "        \"endpoint\": \"/api/step3/upload\",\n",
        "        \"payload\": \"multipart/form-data (file)\"\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step3_convert_cv\",\n",
        "        \"endpoint\": \"/api/step3\",\n",
        "        \"payload\": {\"filename\": \"cv.pdf\"}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step4_rewrite_cv\",\n",
        "        \"endpoint\": \"/api/step4\",\n",
        "        \"payload\": {}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step5_match\",\n",
        "        \"endpoint\": \"/api/step5\",\n",
        "        \"payload\": {}\n",
        "    },\n",
        "    {\n",
        "        \"step\": \"step6_cross_match\",\n",
        "        \"endpoint\": \"/api/step6\",\n",
        "        \"payload\": {}\n",
        "    }\n",
        "]\n",
        "\n",
        "pd.DataFrame(examples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preview\n",
        "\n",
        "Quick look at the raw and rewritten job data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if jobs_raw is not None:\n",
        "    display(jobs_raw.head(3))\n",
        "else:\n",
        "    print(\"Missing data/jobs_raw.csv\")\n",
        "\n",
        "if jobs_rewritten is not None:\n",
        "    display(jobs_rewritten.head(3))\n",
        "else:\n",
        "    print(\"Missing data/jobs_rewritten.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matching results preview\n",
        "\n",
        "Top results from the embedding matcher and cross-encoder reranker.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if matches_embed is not None:\n",
        "    cols = [c for c in [\"Poste\", \"Entreprise\", \"match_score\"] if c in matches_embed.columns]\n",
        "    display(matches_embed[cols].head(5))\n",
        "else:\n",
        "    print(\"Missing data/final_matches.csv\")\n",
        "\n",
        "if matches_cross is not None:\n",
        "    cols = [c for c in [\"Poste\", \"Entreprise\", \"match_score\"] if c in matches_cross.columns]\n",
        "    display(matches_cross[cols].head(5))\n",
        "else:\n",
        "    print(\"Missing data/final_matches_cross.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Precision metrics (proxy labels)\n",
        "\n",
        "If `data/eval_labels.csv` exists, it is used as manual labels (columns:\n",
        "Poste, Entreprise, relevant). Otherwise, this notebook creates proxy labels\n",
        "from keyword overlap between the CV and job text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_path = os.path.join(DATA_DIR, \"eval_labels.csv\")\n",
        "\n",
        "STOPWORDS = set([\n",
        "    \"de\", \"la\", \"le\", \"les\", \"des\", \"du\", \"un\", \"une\",\n",
        "    \"et\", \"ou\", \"en\", \"au\", \"aux\", \"pour\", \"avec\", \"sur\",\n",
        "    \"the\", \"and\", \"for\", \"with\", \"to\", \"in\", \"of\", \"a\", \"an\"\n",
        "])\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[a-z0-9]+\", text.lower())\n",
        "    return [t for t in tokens if t not in STOPWORDS and len(t) > 2]\n",
        "\n",
        "def build_job_text(df):\n",
        "    cols = [\"Poste\", \"Entreprise\", \"Resume_IA\", \"Missions\", \"Profil_Recherche\"]\n",
        "    cols = [c for c in cols if c in df.columns]\n",
        "    if not cols:\n",
        "        return pd.Series([\"\"] * len(df), index=df.index)\n",
        "    return df[cols].fillna(\"\").astype(str).apply(lambda row: \" \".join(row), axis=1)\n",
        "\n",
        "if jobs_rewritten is None:\n",
        "    raise ValueError(\"jobs_rewritten.csv is required for evaluation\")\n",
        "\n",
        "job_text = build_job_text(jobs_rewritten)\n",
        "jobs_eval = jobs_rewritten[[\"Poste\", \"Entreprise\"]].copy()\n",
        "jobs_eval[\"job_text\"] = job_text\n",
        "\n",
        "cv_tokens = set(tokenize(cv_text)) if cv_text else set()\n",
        "if not cv_tokens:\n",
        "    print(\"Warning: CV text missing or empty. Proxy labels may be all zeros.\")\n",
        "\n",
        "if os.path.exists(labels_path):\n",
        "    labels = pd.read_csv(labels_path)\n",
        "    labels[\"relevant\"] = labels[\"relevant\"].astype(int)\n",
        "    jobs_labeled = jobs_eval.merge(labels, on=[\"Poste\", \"Entreprise\"], how=\"left\")\n",
        "    jobs_labeled[\"relevant\"] = jobs_labeled[\"relevant\"].fillna(0).astype(int)\n",
        "    label_source = \"manual\"\n",
        "else:\n",
        "    THRESHOLD = 1\n",
        "    jobs_eval[\"overlap\"] = job_text.apply(lambda t: len(set(tokenize(t)) & cv_tokens))\n",
        "    jobs_eval[\"relevant\"] = (jobs_eval[\"overlap\"] >= THRESHOLD).astype(int)\n",
        "    jobs_labeled = jobs_eval\n",
        "    label_source = \"proxy\"\n",
        "\n",
        "print(f\"Label source: {label_source} (relevant count = {jobs_labeled['relevant'].sum()})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(df, k):\n",
        "    k = min(k, len(df))\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    return float(df.head(k)[\"relevant\"].mean())\n",
        "\n",
        "def average_precision(df):\n",
        "    rel = df[\"relevant\"].values\n",
        "    precisions = []\n",
        "    hit = 0\n",
        "    for i, r in enumerate(rel, start=1):\n",
        "        if r:\n",
        "            hit += 1\n",
        "            precisions.append(hit / i)\n",
        "    return float(np.mean(precisions)) if precisions else 0.0\n",
        "\n",
        "def compute_metrics(ranked_df, label_df, name):\n",
        "    merged = ranked_df.merge(\n",
        "        label_df[[\"Poste\", \"Entreprise\", \"relevant\"]],\n",
        "        on=[\"Poste\", \"Entreprise\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        "    merged[\"relevant\"] = merged[\"relevant\"].fillna(0).astype(int)\n",
        "    metrics = {\n",
        "        \"model\": name,\n",
        "        \"precision_at_5\": precision_at_k(merged, 5),\n",
        "        \"precision_at_10\": precision_at_k(merged, 10),\n",
        "        \"avg_precision\": average_precision(merged),\n",
        "    }\n",
        "    return metrics, merged\n",
        "\n",
        "metrics_rows = []\n",
        "ranked_frames = {}\n",
        "\n",
        "if matches_embed is not None:\n",
        "    metrics, merged = compute_metrics(matches_embed, jobs_labeled, \"embedding_match\")\n",
        "    metrics_rows.append(metrics)\n",
        "    ranked_frames[\"embedding_match\"] = merged\n",
        "\n",
        "if matches_cross is not None:\n",
        "    metrics, merged = compute_metrics(matches_cross, jobs_labeled, \"cross_encoder\")\n",
        "    metrics_rows.append(metrics)\n",
        "    ranked_frames[\"cross_encoder\"] = merged\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_rows)\n",
        "metrics_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not metrics_df.empty:\n",
        "    metrics_plot = metrics_df.set_index(\"model\")[\n",
        "        [\"precision_at_5\", \"precision_at_10\", \"avg_precision\"]\n",
        "    ]\n",
        "    metrics_plot.plot(kind=\"bar\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(\"Precision metrics (proxy labels)\")\n",
        "    plt.ylabel(\"score\")\n",
        "    plt.tight_layout()\n",
        "else:\n",
        "    print(\"No metrics to plot.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latency benchmark\n",
        "\n",
        "Set `RUN_HEAVY = True` to benchmark the full embedding and cross-encoder\n",
        "models. With `RUN_HEAVY = False`, the notebook measures lightweight\n",
        "operations as a proxy so the chart still renders quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_HEAVY = False\n",
        "\n",
        "def time_call(label, fn):\n",
        "    start = time.perf_counter()\n",
        "    result = fn()\n",
        "    end = time.perf_counter()\n",
        "    return {\"step\": label, \"seconds\": end - start, \"result\": result}\n",
        "\n",
        "latency_tasks = []\n",
        "\n",
        "if RUN_HEAVY:\n",
        "    from services.matcher import calculate_matches\n",
        "    from services.cross_encoder_matcher import calculate_cross_matches\n",
        "\n",
        "    latency_tasks.append((\n",
        "        \"embedding_match\",\n",
        "        lambda: calculate_matches(\n",
        "            cv_txt_path=cv_path,\n",
        "            jobs_csv_path=jobs_rewritten_path,\n",
        "            progress_callback=None,\n",
        "        ),\n",
        "    ))\n",
        "    latency_tasks.append((\n",
        "        \"cross_encoder\",\n",
        "        lambda: calculate_cross_matches(\n",
        "            cv_txt_path=cv_path,\n",
        "            jobs_csv_path=jobs_rewritten_path,\n",
        "            progress_callback=None,\n",
        "        ),\n",
        "    ))\n",
        "else:\n",
        "    if os.path.exists(jobs_rewritten_path):\n",
        "        latency_tasks.append((\"load_jobs_rewritten\", lambda: pd.read_csv(jobs_rewritten_path)))\n",
        "    if os.path.exists(cv_path):\n",
        "        latency_tasks.append((\"load_cv\", lambda: open(cv_path, \"r\", encoding=\"utf-8\").read()))\n",
        "    if matches_embed is not None:\n",
        "        latency_tasks.append((\n",
        "            \"rank_top_5\",\n",
        "            lambda: matches_embed.sort_values(\"match_score\", ascending=False).head(5)\n",
        "        ))\n",
        "\n",
        "latencies = []\n",
        "for label, fn in latency_tasks:\n",
        "    latencies.append(time_call(label, fn))\n",
        "\n",
        "lat_df = pd.DataFrame(latencies)\n",
        "if not lat_df.empty:\n",
        "    lat_df[\"ms\"] = lat_df[\"seconds\"] * 1000\n",
        "    display(lat_df[[\"step\", \"ms\"]].sort_values(\"ms\", ascending=False))\n",
        "    lat_df.plot(kind=\"bar\", x=\"step\", y=\"ms\", legend=False)\n",
        "    plt.ylabel(\"latency (ms)\")\n",
        "    plt.title(\"Latency by step\")\n",
        "    plt.tight_layout()\n",
        "else:\n",
        "    print(\"No latency tasks to run.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
